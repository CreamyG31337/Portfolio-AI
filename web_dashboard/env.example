# Environment Variables for Web Dashboard
# Copy this file to .env and fill in your values
# The .env file is gitignored and will not be committed to version control

# ============================================================
# Required: Supabase Configuration
# ============================================================
# Your Supabase project URL
SUPABASE_URL=https://your-project.supabase.co

# Supabase publishable/anon key (for user authentication)
SUPABASE_PUBLISHABLE_KEY=your-publishable-key-here
# Alternative name (for backwards compatibility)
SUPABASE_ANON_KEY=your-publishable-key-here

# Supabase service role/secret key (for admin operations, bypasses RLS)
# Only needed for admin scripts and debug operations
SUPABASE_SECRET_KEY=your-secret-key-here
# Alternative name (for backwards compatibility)
SUPABASE_SERVICE_ROLE_KEY=your-secret-key-here

# ============================================================
# Required: Application Domain
# ============================================================
# Your application domain (e.g., "ai-trading.drifting.space" or "drifting.space")
# Used for:
# - Magic link and password reset email redirects
# - Cookie domain settings
# - Caddyfile configuration
APP_DOMAIN=your-domain.com

# Optional: Override magic link redirect URL (defaults to https://{APP_DOMAIN}/auth_callback.html)
# MAGIC_LINK_REDIRECT_URL=https://your-domain.com/auth_callback.html

# ============================================================
# Optional: Research Database (Postgres)
# ============================================================
# Postgres connection string for research articles storage
# Format: postgresql://user:password@host:port/database
# For Docker containers connecting to host Postgres: use host.docker.internal
# Example: postgresql://postgres:password@host.docker.internal:5432/trading_db
# RESEARCH_DATABASE_URL=postgresql://user:password@host:port/database

# ============================================================
# Optional: Supabase PostgreSQL Connection (for APScheduler)
# ============================================================
# PostgreSQL connection string for SQLAlchemyJobStore
# 
# IMPORTANT: Supabase direct connections use IPv6 only. If your network doesn't support IPv6,
# use the Connection Pooler (Supavisor) which provides IPv4 addresses.
#
# Get from Supabase Dashboard: Settings → Database → Connection Pooling
# Use "Transaction Mode" connection string (port 6543) for best compatibility
# Format: postgresql://postgres.[PROJECT_REF]:[PASSWORD]@aws-0-[REGION].pooler.supabase.com:6543/postgres
#
# Alternative: Direct connection (IPv6 only, may not work in all networks)
# Format: postgresql://postgres:[PASSWORD]@db.[PROJECT_REF].supabase.co:5432/postgres
#
# SUPABASE_DATABASE_URL=postgresql://postgres.[PROJECT_REF]:[PASSWORD]@aws-0-[REGION].pooler.supabase.com:6543/postgres

# ============================================================
# Optional: Financial Modeling Prep API
# ============================================================
# API key for congress trading module
# Get from: https://site.financialmodelingprep.com/developer/docs/
# Required for congress_trades scheduled job
# FMP_API_KEY=your-fmp-api-key-here

# ============================================================
# Optional: Zhipu / Z.AI (GLM-4.7) API Key
# ============================================================
# Which API (both use same key, same OpenAI-style /chat/completions):
#   1) OpenAI-compatible (default): https://api.z.ai/api/coding/paas/v4
#      – Z.AI Coding Plan, good for code and general use.
#   2) Zhipu open platform: https://open.bigmodel.cn/api/paas/v4
#      – Set ZHIPU_BASE_URL to this if your key works better here.
# Get key: https://open.bigmodel.cn/ or Z.AI Coding Plan.
# Can also be set via AI Settings UI (saved to .secrets).
# ZHIPU_API_KEY=your-zhipu-api-key-here
# GLM_4_API_KEY=your-zhipu-api-key-here
# ZHIPU_BASE_URL=https://open.bigmodel.cn/api/paas/v4

# ============================================================
# Optional: Ollama AI Configuration
# ============================================================
# Ollama API URL (default: http://host.docker.internal:11434 for Docker)
# OLLAMA_BASE_URL=http://host.docker.internal:11434

# Default AI model (default: mistral-nemo:12b)
# OLLAMA_MODEL=mistral-nemo:12b

# Enable AI assistant (default: true)
# OLLAMA_ENABLED=true

# ============================================================
# Optional: FlareSolverr Configuration
# ============================================================
# FlareSolverr URL for bypassing Cloudflare. Used by RSS feed ingest, social sentiment, congress trades.
# Configure this only in your local .env (gitignored), not in code.
# Examples:
#   FLARESOLVERR_URL=http://your-server-hostname:8191
#   FLARESOLVERR_URL=http://host.docker.internal:8191
# FLARESOLVERR_URL=http://your-server-hostname:8191

# ============================================================
# Optional: Robots.txt Enforcement
# ============================================================
# Enable robots.txt compliance checks for all HTTP-fetching jobs.
# When enabled (set to "1", "true", "yes", "on", or "enabled"), jobs will check
# robots.txt before accessing external URLs and abort if disallowed.
# Default: disabled (unset or empty) - jobs run normally without robots.txt checks.
# ENABLE_ROBOTS_TXT_CHECKS=0

# ============================================================
# Optional: WebAI Service Configuration (WebAI Pro)
# ============================================================
# Cookie-based authentication for web AI service
# Option 1: JSON string containing all cookies
# WEBAI_COOKIES_JSON={"__Secure-1PSID":"...","__Secure-1PSIDTS":"..."}
#
# Option 2: Individual cookie values (alternative to JSON)
# WEBAI_SECURE_1PSID=your-secure-1psid-value
# WEBAI_SECURE_1PSIDTS=your-secure-1psidts-value
#
# Note: For local development, cookies can be loaded from webai_cookies.json file
# For production, use environment variables (set in Woodpecker secrets)

# ============================================================
# Optional: AI Service Keyfile Configuration
# ============================================================
# These variables are used when generating ai_service.keys.json
# They obfuscate service URLs and display names to keep them out of git
# 
# Encryption key for obfuscation (set a strong key in production)
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
# AI_SERVICE_KEY=your-encryption-key-here
#
# Service URLs (obfuscated in keyfile)
# Web interface URL for cookie-based access (hint: search for "AI chat" + "google")
# AI_SERVICE_WEB_URL=https://example-ai-service.com/app
# Model identifier (hint: service name + "-pro")
# AI_SERVICE_MODEL_NAME=example-ai-pro
#
# Model display names (shown to users, obfuscated in keyfile)
# Format: Service Name + version + variant
# MODEL_DISPLAY_2_5_FLASH=Example AI 2.5 Flash
# MODEL_DISPLAY_2_5_PRO=Example AI 2.5 Pro
# MODEL_DISPLAY_3_0_PRO=Example AI 3.0 Pro
#
# Note: These values are only used when running create_ai_service_keys.py
# The generated keyfile (ai_service.keys.json) is gitignored

# ============================================================
# Optional: Shared Cookies Directory (Local Development)
# ============================================================
# Directory path for cookie files and logs (default: /shared/cookies for Docker)
# Override this for local development without Docker volumes
# SHARED_COOKIES_DIR=/path/to/local/cookies

# ============================================================
# Optional: Research Report Server Upload (Local Development)
# ============================================================
# Server configuration for uploading PDFs when running locally
# Only needed if you want to automatically upload processed PDFs to server
# RESEARCH_SERVER_HOST=your-server.com
# RESEARCH_SERVER_USER=your-username
# RESEARCH_SERVER_PATH=/home/user/ai-trading-www/research  # Path where web server serves PDFs
# RESEARCH_SSH_KEY_PATH=C:/path/to/your/ssh/key  # Optional, for key-based auth

# ============================================================
# Build Configuration (set by CI/CD)
# ============================================================
# Build timestamp (automatically set by Woodpecker CI)
# Used for cache invalidation
# BUILD_TIMESTAMP=2024-01-01 12:00 UTC
